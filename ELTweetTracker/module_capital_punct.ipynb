{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import string\n",
    "from pandas import read_csv\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from collections import Iterable\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import NE_candidate_module as ne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------Existing Lists--------------------\n",
    "cachedStopWords = set(stopwords.words(\"english\"))\n",
    "cachedStopWords.update((\"and\",\"make\",\"oh\",\"via\",\"i\",\"i'll\",\"would\",\"should\",\"shall\",\"hasn't\",\"wasn't\",\"also\",\"let's\",\"let\",\"well\",\"just\",\"someone\",\"theres\",\"somebody\",\"didn't\",\"i've\",\"they're\",\"we're\",\"we'll\",\"we've\",\"they've\",\"they'd\",\"they'll\",\"again\",\"you're\",\"thats\",\"that's\",\"i'm\",\"a\",\"so\",\"except\",\"arn't\",\"aren't\",\"arent\",\"this\",\"when\",\"it\",\"it's\",\"he's\",\"she's\",\"she'd\",\"he'd\",\"he'll\",\"she'll\",\"many\",\"can't\",\"even\",\"cant\",\"yes\",\"no\",\"these\",\"here\",\"there\",\"to\",\"may\",\"maybe\",\"<hashtag>\",\"<hashtag>.\",\"ever\",\"every\",\"never\",\"there's\",\"there’s\"))\n",
    "cachedTitles = [\"Mr.\",\"Mr\",\"Mrs.\",\"Mrs\",\"Miss\",\"Ms\",\"Sen.\"]\n",
    "prep_list=[\"in\",\"at\",\"of\",\"on\",\"and\",\"by\"] #includes common conjunction as well\n",
    "article_list=[\"a\",\"an\",\"the\"]\n",
    "day_list=[\"sunday\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"mon\",\"tues\",\"wed\",\"thurs\",\"fri\",\"sat\",\"sun\"]\n",
    "month_list=[\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\",\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "chat_word_list=[\"thank\",\"thanks\",\"congrats\",\"whoa\",\"hey\",\"hi\",\"huh\",\"fyi\",\"duh\",\"damn\",\"lol\",\"omg\",\"congratulations\",\"fuck\",\"wtf\",\"wtaf\",\"xoxo\",\"rofl\",\"imo\",\"wow\",\"fck\",\"haha\",\"hehe\",\"hoho\"]\n",
    "#---------------------Existing Lists--------------------\n",
    "NE_container={}\n",
    "\n",
    "def insert_dict(key):\n",
    "    #print(key)\n",
    "    if key in NE_container:\n",
    "        NE_container[key] += 1\n",
    "    else:\n",
    "        NE_container[key] = 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printList(mylist):\n",
    "    print(\"[\"),\n",
    "    #print \"[\",\n",
    "    for item in mylist:\n",
    "        if item != None:\n",
    "            if isinstance(item,ne.NE_candidate):\n",
    "                item.print_obj()\n",
    "                #print (item.phraseText)\n",
    "            else:\n",
    "                print (item+\",\", end=\"\")\n",
    "                #print item+\",\",\n",
    "    #print \"]\"\n",
    "    print(\"]\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(mylist, outlist,ignore_types=(str, bytes, ne.NE_candidate)):\n",
    "    \n",
    "    if mylist !=[]:\n",
    "        for item in mylist:\n",
    "            #print not isinstance(item, ne.NE_candidate)\n",
    "            if isinstance(item, list) and not isinstance(item, ignore_types):\n",
    "                flatten(item, outlist)\n",
    "            else:\n",
    "                if isinstance(item,ne.NE_candidate):\n",
    "                    item.phraseText=item.phraseText.strip(' \\t\\n\\r')\n",
    "                    item.reset_length()\n",
    "                else:\n",
    "                    item=item.strip(' \\t\\n\\r')\n",
    "                outlist.append(item)\n",
    "    return outlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consecutive_cap(tweetWordList_cappos,tweetWordList):\n",
    "    output=[]\n",
    "    #identifies consecutive numbers in the sequence\n",
    "    for k, g in groupby(enumerate(tweetWordList_cappos), lambda element: element[0]-element[1]):\n",
    "        output.append(list(map(itemgetter(1), g)))\n",
    "    count=0\n",
    "    if output:        \n",
    "        final_output=[output[0]]\n",
    "        for first, second in (zip(output,output[1:])):\n",
    "            if ((second[0]-first[-1])==2) & (tweetWordList[first[-1]+1].lower() in prep_list):\n",
    "                (final_output[-1]).extend([first[-1]+1]+second)\n",
    "            elif((second[0]-first[-1])==3) & (tweetWordList[first[-1]+1].lower() in prep_list)& (tweetWordList[first[-1]+2].lower() in article_list):\n",
    "                (final_output[-1]).extend([first[-1]+1]+[first[-1]+2]+second)\n",
    "            else:\n",
    "                final_output.append(second)\n",
    "                #merge_positions.append(False)\n",
    "    else:\n",
    "        final_output=[]\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#basically splitting the original NE_candidate text and building individual object from each text snippet\n",
    "def build_custom_NE(phrase,pos,prototype,feature_index,feature_value):\n",
    "    #print(\"Enters\")\n",
    "    position=pos\n",
    "    custom_NE= ne.NE_candidate(phrase,position)\n",
    "    for i in range(14):\n",
    "        custom_NE.set_feature(i,prototype.features[i])\n",
    "    custom_NE.set_feature(feature_index,feature_value)\n",
    "    if (feature_index== ne.is_csl) & (feature_value== True):\n",
    "        custom_NE.set_feature(ne.start_of_sentence, False)\n",
    "    custom_NE=entity_info_check(custom_NE)\n",
    "    return custom_NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abbrv_algo(ne_element):\n",
    "    '''abbreviation algorithm \n",
    "    trailing apostrophe:\n",
    "           |period:\n",
    "           |     multiple letter-period sequence:\n",
    "           |         all caps\n",
    "           | non period:\n",
    "           |     ?/! else drop apostrophe\n",
    "    else:\n",
    "        unchanged\n",
    "    '''\n",
    "    phrase= ne_element.phraseText\n",
    "    #print(\"=>\"+phrase)\n",
    "    #since no further split occurs we can set remaining features now\n",
    "    ne_element.set_feature(ne.capitalized, True)\n",
    "    if ne_element.phraseText.isupper():\n",
    "        ne_element.set_feature(ne.all_capitalized, True)\n",
    "    else:\n",
    "        ne_element.set_feature(ne.all_capitalized, False)\n",
    "        \n",
    "    abbreviation_flag=False\n",
    "    p=re.compile(r'[^a-zA-Z\\d\\s]$')\n",
    "    match_list = p.findall(phrase)\n",
    "    if len(match_list)>0:\n",
    "        #print(\"Here\")\n",
    "        if phrase.endswith('.'):\n",
    "            p1= re.compile(r'([a-zA-Z][\\.]\\s*)')\n",
    "            match_list = p1.findall(phrase)\n",
    "            if ((len(match_list)>1) & (len(phrase)<6)):\n",
    "                #print (\"1. Found abbreviation: \"+phrase)\n",
    "                abbreviation_flag= True\n",
    "            else:\n",
    "                phrase= phrase[:-1]\n",
    "        else:\n",
    "            phrase= phrase[:-1]\n",
    "            #if not (phrase.endswith('?')|phrase.endswith('!')|phrase.endswith(')')|phrase.endswith('>')):\n",
    "                #phrase= phrase[:-1]\n",
    "    else:\n",
    "        p2=re.compile(r'([^a-zA-Z0-9_\\s])')\n",
    "        match_list = p2.findall(phrase)\n",
    "        if ((len(match_list)==0) & (phrase.isupper()) & (len(phrase)<7)& (len(phrase)>1)):\n",
    "            #print (\"2. Found abbreviation!!: \"+phrase)\n",
    "            abbreviation_flag= True\n",
    "        else:\n",
    "            #print(\"Here-> \"+phrase)\n",
    "            p3= re.compile(r'([A-Z][.][A-Z])')\n",
    "            p4= re.compile(r'\\s')\n",
    "            match_list = p3.findall(phrase)\n",
    "            match_list1 = p4.findall(phrase)\n",
    "            if ((len(match_list)>0) & (len(match_list1)==0)):\n",
    "                abbreviation_flag= True\n",
    "                print (\"3. Found abbreviation!!: \"+phrase)\n",
    "            \n",
    "    #element= ne.NE_candidate(phrase.strip())\n",
    "    ne_element.phraseText=phrase\n",
    "    ne_element.reset_length()\n",
    "    ne_element.set_feature(ne.abbreviation, abbreviation_flag)\n",
    "    return ne_element\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def punct_clause(NE_phrase_in):\n",
    "    \n",
    "    NE_phrases=entity_info_check(NE_phrase_in)\n",
    "    cap_phrases=NE_phrases.phraseText.strip()\n",
    "    #print (cap_phrases)\n",
    "    if (re.compile(r'[^a-zA-Z0-9_\\s]')).findall(cap_phrases):\n",
    "        #case of intermediate punctuations: handles abbreviations\n",
    "        p1= re.compile(r'(?:[a-zA-Z0-9][^a-zA-Z0-9_\\s]\\s*)')\n",
    "        match_lst = p1.findall(cap_phrases)\n",
    "        if match_lst:\n",
    "            index= (list( p1.finditer(cap_phrases) )[-1]).span()[1]\n",
    "        \n",
    "        p= re.compile(r'[^a-zA-Z\\d\\s]')\n",
    "        match_list = p.findall(cap_phrases)\n",
    "\n",
    "        p2=re.compile(r'[^a-zA-Z\\d\\s]$') #ends with punctuation\n",
    "\n",
    "        if len(match_list)-len(match_lst)>0:\n",
    "            if (p2.findall(cap_phrases)):\n",
    "                #only strips trailing punctuations, not intermediate ones following letters\n",
    "                cap_phrases = cap_phrases[0:index]+re.sub(p, '', cap_phrases[index:])\n",
    "                NE_phrases.phraseText= cap_phrases\n",
    "        \n",
    "    \n",
    "    #comma separated NEs\n",
    "    #lst=filter(lambda(word): word!=\"\", re.split('[,]', cap_phrases))\n",
    "    start_of_sentence_fix=NE_phrases.features[ne.start_of_sentence]\n",
    "    wordlst=list(filter(lambda word: word!=\"\", re.split('[,]', cap_phrases)))\n",
    "    if (NE_phrases.features[ne.date_indicator]==False) & (len(wordlst)>1):\n",
    "        pos=NE_phrases.position\n",
    "        combined=[]\n",
    "        prev=0\n",
    "        for i in range(len(wordlst)):\n",
    "            word=wordlst[i]\n",
    "            word_len=len(list(filter(lambda individual_word: individual_word!=\"\", re.split('[ ]', word))))\n",
    "            word_pos=pos[(prev):(prev+word_len)]\n",
    "            prev=prev+word_len\n",
    "            combined+=[[word]+word_pos]\n",
    "        \n",
    "        lst_nsw=list(filter(lambda element: (((str(element[0])).lower() not in cachedStopWords) & (len(str(element[0]))>1)) ,combined))\n",
    "        #print (lst_nsw)\n",
    "        final_lst= list(map(lambda element:build_custom_NE(str(element[0]),element[1:],NE_phrases,ne.is_csl,True), lst_nsw))\n",
    "        final_lst[0].set_feature(ne.start_of_sentence, NE_phrases.features[ne.start_of_sentence])\n",
    "    else:\n",
    "        NE_phrases.set_feature(ne.is_csl,False)\n",
    "        final_lst=[NE_phrases]\n",
    "    \n",
    "    #check abbreviation\n",
    "    final_lst= list(map(lambda phrase: abbrv_algo(phrase), final_lst))\n",
    "\n",
    "    \n",
    "    #print(lst)\n",
    "    return final_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -o\n",
    "def f(x,tweetWordList):\n",
    "\n",
    "    #list1=map(lambda word: check(tweetWordList[word], word), x)\n",
    "    list1=list(map(lambda word: tweetWordList[word]+\" \", x[:-1]))\n",
    "    phrase=\"\".join(list1)+tweetWordList[x[-1]]\n",
    "\n",
    "    if not ((phrase[0].isdigit()) & (len(x)==1)):\n",
    "        NE_phrase= ne.NE_candidate(phrase.strip(),x)\n",
    "        if 0 in x:\n",
    "            NE_phrase.set_feature(ne.start_of_sentence,True)\n",
    "        else:\n",
    "            NE_phrase.set_feature(ne.start_of_sentence,False)\n",
    "    else:\n",
    "        NE_phrase= ne.NE_candidate(\"JUST_DIGIT_ERROR\",[])\n",
    "\n",
    "    return NE_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def capCheck(word):\n",
    "    combined_list=[]+list(cachedStopWords)+prep_list+chat_word_list\n",
    "    if word.startswith('@'):\n",
    "        return False\n",
    "    elif \"<Hashtag\" in word:\n",
    "        return False\n",
    "    elif ((word.lstrip(string.punctuation)).rstrip(string.punctuation)).lower() in combined_list:\n",
    "        if(word!=\"The\"):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    elif word[0].isdigit():\n",
    "        return True\n",
    "    else:\n",
    "        p=re.compile(r'^[\\W]*[A-Z]')\n",
    "        l= p.match(word)\n",
    "        if l:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_check(ne_phrase):\n",
    "    title_flag=False\n",
    "    words=ne_phrase.phraseText.split()\n",
    "    for word in words:\n",
    "        if word in cachedTitles:\n",
    "            title_flag= True\n",
    "            break\n",
    "    ne_phrase.set_feature(ne.title,title_flag)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entity_info_check(ne_phrase):\n",
    "    flag1=False #has number\n",
    "    flag3=False\n",
    "    flag_ind=[] #is number\n",
    "    month_ind=[]\n",
    "    date_num_holder=[]\n",
    "    words=ne_phrase.phraseText.split()\n",
    "    for word in words:\n",
    "        word=(word.strip()).rstrip(string.punctuation).lower()\n",
    "        if not word.isalpha():\n",
    "            flag_ind+=[True]\n",
    "            if word.isdigit():\n",
    "                date_num_holder+=['num']\n",
    "            else:\n",
    "                date_num_holder+=['alpha']\n",
    "        else:\n",
    "            flag_ind+=[False]\n",
    "            if word in month_list:\n",
    "                month_ind+=[True]\n",
    "                date_num_holder+=['month']\n",
    "            elif word in day_list:\n",
    "                date_num_holder+=['day']\n",
    "            elif word in prep_list:\n",
    "                date_num_holder+=['preposition']\n",
    "            elif word in article_list:\n",
    "                date_num_holder+=['article']\n",
    "            else:\n",
    "                #print(\"=>\"+word)\n",
    "                date_num_holder+=['string']\n",
    "    if True in flag_ind:\n",
    "        flag1=True\n",
    "    if True in month_ind:\n",
    "        flag3=True\n",
    "    ne_phrase.set_feature(ne.has_number,flag1)\n",
    "    ne_phrase.set_feature(ne.date_indicator,flag3)\n",
    "    ne_phrase.set_date_num_holder(date_num_holder)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#removing commonly used expletives, enunciated chat words and other common words (like days of the week, common expressions)\n",
    "def slang_remove(ne_phrase):\n",
    "    phrase=(ne_phrase.phraseText.strip()).rstrip(string.punctuation).lower()\n",
    "    p1= re.compile(r'([A-Za-z]+)\\1\\1{1,}')\n",
    "    match_lst = p1.findall(phrase)\n",
    "    if phrase in article_list:\n",
    "        return True\n",
    "    elif phrase in day_list:\n",
    "        return True\n",
    "    elif phrase in month_list:\n",
    "        return True\n",
    "    elif match_lst:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apostrope_check(ne_phrase):\n",
    "    apostrophe=\"'s\"\n",
    "    bad_apostrophe=\"’s\"\n",
    "    phrase=(ne_phrase.phraseText.strip()).rstrip(string.punctuation).lower()\n",
    "    if ((apostrophe in phrase) |(bad_apostrophe in phrase)):\n",
    "        if phrase.endswith(apostrophe):\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,0)\n",
    "        else:\n",
    "            #print(phrase.find(apostrophe))\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,phrase.find(apostrophe))\n",
    "\n",
    "        if phrase.endswith(bad_apostrophe):\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,0)\n",
    "        else:\n",
    "            #print(phrase.find(apostrophe))\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,phrase.find(bad_apostrophe))\n",
    "    else:\n",
    "        ne_phrase.set_feature(ne.is_apostrophed,-1)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def punctuation_check(ne_phrase):\n",
    "    holder=[]\n",
    "    punctuation_holder=[]\n",
    "    flag_holder=[]\n",
    "    phrase=(ne_phrase.phraseText.strip()).rstrip(string.punctuation).lower()\n",
    "    for i in range(len(phrase)):\n",
    "        if (phrase[i] in string.punctuation):\n",
    "            holder+=[i]\n",
    "    for i in holder:\n",
    "        if ((i<(len(phrase)-1)) & (phrase[i]==\"'\") & (phrase[i+1]==\"s\")):\n",
    "            flag_holder+=[False]\n",
    "        elif ((i==(len(phrase)-1)) & (phrase[i]==\"'\")):\n",
    "            flag_holder+=[False]\n",
    "        else:\n",
    "            flag_holder+=[True]\n",
    "            punctuation_holder+=[i]\n",
    "    #print(flag_holder)\n",
    "    ne_phrase.set_punctuation_holder(punctuation_holder)\n",
    "    if True in flag_holder:\n",
    "        ne_phrase.set_feature(ne.has_intermediate_punctuation,True)\n",
    "    else:\n",
    "        ne_phrase.set_feature(ne.has_intermediate_punctuation,False)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tense_check(ne_phrase):\n",
    "    words=(((ne_phrase.phraseText.strip()).rstrip(string.punctuation)).lower()).split()\n",
    "    verb_flag=False\n",
    "    adverb_flag=False\n",
    "    if (len(words)==1):\n",
    "        if words[0].endswith(\"ing\"):\n",
    "            verb_flag=True\n",
    "        if words[0].endswith(\"ly\"):\n",
    "            adverb_flag=True\n",
    "    ne_phrase.set_feature(ne.ends_like_verb,verb_flag)\n",
    "    ne_phrase.set_feature(ne.ends_like_adverb,adverb_flag)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def capitalization_change(ne_element):\n",
    "    phrase=((ne_element.phraseText.lstrip(string.punctuation)).rstrip(string.punctuation)).strip()\n",
    "    val=-1\n",
    "    topic_indicator=False\n",
    "    p1= re.compile(r'[A-Z]*\\s*[A-Z]{4,}[^A-Za-z]*\\s+[A-Za-z]+') #BREAKING: Toronto Raptors\n",
    "    p2= re.compile(r'([A-Z]{1}[a-z]+)+[^A-Za-z]*\\s+[A-Z]{4,}') #The DREAMIEST LAND\n",
    "    match_lst1 = p1.findall(phrase)\n",
    "    match_lst2 = p2.findall(phrase)\n",
    "    if (match_lst1):\n",
    "        if not phrase.isupper():\n",
    "            p3=re.compile(r'[A-Z]*\\s*[A-Z]{4,}[^A-Za-z]*\\s+')\n",
    "            val=list(p3.finditer(phrase))[-1].span()[1]\n",
    "            if(\":\" in phrase):\n",
    "                topic_indicator=True\n",
    "            ne_element.set_feature(ne.change_in_capitalization,val)\n",
    "    elif (match_lst2):\n",
    "        #print (\"GOTIT2: \"+phrase)\n",
    "        p3=re.compile(r'([A-Z]{1}[a-z]+)+')\n",
    "        val=list(p3.finditer(phrase))[-1].span()[1]\n",
    "        ne_element.set_feature(ne.change_in_capitalization,val)\n",
    "    else:\n",
    "        ne_element.set_feature(ne.change_in_capitalization,val)\n",
    "    ne_element.set_feature(ne.has_topic_indicator,topic_indicator)\n",
    "    return ne_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trueEntity_process(tweetWordList_cappos,tweetWordList):\n",
    "    \n",
    "    #returns list with position of consecutively capitalized words\n",
    "    output = consecutive_cap(tweetWordList_cappos,tweetWordList)\n",
    "\n",
    "    #consecutive capitalized phrases \n",
    "    consecutive_cap_phrases1=list(map(lambda x: f(x,tweetWordList), output))\n",
    "\n",
    "    consecutive_cap_phrases=list(filter(lambda candidate:(candidate.phraseText!=\"JUST_DIGIT_ERROR\"),consecutive_cap_phrases1))\n",
    "\n",
    "    \n",
    "    #implement the punctuation clause\n",
    "    ne_List_pc=flatten(list(map(lambda NE_phrase: punct_clause(NE_phrase), consecutive_cap_phrases)),[])\n",
    "    \n",
    "\n",
    "    #implement title detection\n",
    "    ne_List_titleCheck= list(map(lambda element: title_check(element), ne_List_pc))\n",
    "    \n",
    "    #implement slang check and remove\n",
    "    ne_List_slangCheck= list(filter(lambda element: not slang_remove(element), ne_List_titleCheck))\n",
    "    \n",
    "    #implement apostrophe, tense and punctuation marker with final number check\n",
    "    ne_List_apostropeCheck= list(map(lambda element: apostrope_check(element), ne_List_slangCheck))\n",
    "    ne_List_punctuationCheck= list(map(lambda element: punctuation_check(element), ne_List_apostropeCheck))\n",
    "    ne_List_numCheck=list(filter(lambda candidate: not (candidate.phraseText.lstrip(string.punctuation).rstrip(string.punctuation).strip()).isdigit(), ne_List_punctuationCheck))\n",
    "    ne_List_tenseCheck= list(map(lambda element: tense_check(element), ne_List_numCheck))\n",
    "    \n",
    "    #tracking sudden change in capitalization pattern\n",
    "    ne_List_allCheck= list(map(lambda element: capitalization_change(element), ne_List_tenseCheck))\n",
    "    \n",
    "    return ne_List_allCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sean spicer : 60\n",
      "kyle lowry : 58\n",
      "kurt busch : 16\n",
      "trump : 12\n",
      "white house : 10\n",
      "moonlight : 9\n",
      "spicer : 8\n",
      "oscar : 8\n",
      "best picture : 8\n",
      "russia : 7\n",
      "raptor : 7\n",
      "aim : 7\n",
      "la la land : 6\n",
      "nascar : 5\n",
      "knick : 5\n",
      "russian : 4\n",
      "live : 4\n",
      "kurt : 4\n",
      "daytona 500 : 4\n",
      "breaking: raptor : 4\n",
      "yemen : 3\n",
      "toronto : 3\n",
      "the raptor : 3\n",
      "sean : 3\n",
      "rt : 3\n",
      "really : 3\n",
      "pathological liar sean spicer : 3\n",
      "new : 3\n",
      "muslim : 3\n",
      "mahershala ali : 3\n",
      "lowry : 3\n",
      "id : 3\n",
      "east : 3\n",
      "cia : 3\n",
      "cbs : 3\n",
      "breaking: kyle lowry : 3\n",
      "warren beatty : 2\n",
      "tv : 2\n",
      "the white helmet : 2\n",
      "steve harvey : 2\n",
      "stay : 2\n",
      "snl : 2\n",
      "sean spicer’ : 2\n",
      "sean spicer \"donald trump : 2\n",
      "sean sphincter : 2\n",
      "say : 2\n",
      "remember : 2\n",
      "president : 2\n",
      "playoff : 2\n",
      "last : 2\n",
      "kyle busch : 2\n",
      "keep : 2\n",
      "huge : 2\n",
      "here : 2\n",
      "great : 2\n",
      "gop : 2\n",
      "good : 2\n",
      "ford : 2\n",
      "find leaker : 2\n",
      "emma stone : 2\n",
      "donald trump : 2\n",
      "demar derozan : 2\n",
      "damien chazelle : 2\n",
      "dale earnhardt jr : 2\n",
      "casey affleck : 2\n",
      "busch : 2\n",
      "big : 2\n",
      "best actre : 2\n",
      "best : 2\n",
      "benghazi : 2\n",
      "all-star kyle lowry : 2\n",
      "97.4 ft : 2\n",
      "51.4 fg : 2\n",
      "–sean spicer : 1\n",
      "wsj and wapost : 1\n",
      "wrist surgery : 1\n",
      "wrist : 1\n",
      "wp and cnn : 1\n",
      "worldwide : 1\n",
      "winner : 1\n",
      "whitehouse press secretary sean spicer : 1\n",
      "whitehouse : 1\n",
      "white house press briefing : 1\n",
      "white helmet : 1\n",
      "wh : 1\n",
      "west wing “leak crackdown : 1\n",
      "west wing : 1\n",
      "wendy : 1\n",
      "welcome drose : 1\n",
      "welcome : 1\n",
      "week 1 : 1\n",
      "wasn’t : 1\n",
      "warren : 1\n",
      "want : 1\n",
      "venn : 1\n",
      "vega : 1\n",
      "vanity fair party : 1\n",
      "update: crash : 1\n",
      "update : 1\n",
      "unfortunately : 1\n",
      "undergo wrist surgery : 1\n",
      "unbelievable : 1\n",
      "uk : 1\n",
      "uber's svp : 1\n",
      "u : 1\n",
      "twitter explodes : 1\n",
      "tune-in : 1\n",
      "tune : 1\n",
      "trying : 1\n",
      "trump’s tuesday : 1\n",
      "trumped : 1\n",
      "trump russia : 1\n",
      "trump and xi talked : 1\n",
      "tough : 1\n",
      "toronto raptor : 1\n",
      "top 10 : 1\n",
      "took : 1\n",
      "tonyoldman41: dream : 1\n",
      "today : 1\n",
      "tl : 1\n",
      "time : 1\n",
      "tim tebow : 1\n",
      "throwback : 1\n",
      "thrilling : 1\n",
      "thought : 1\n",
      "the washington post : 1\n",
      "the right scoop : 1\n",
      "the france : 1\n",
      "the dreamiest : 1\n",
      "thankful : 1\n",
      "texas april 9th : 1\n",
      "terrorist : 1\n",
      "taraji : 1\n",
      "take : 1\n",
      "syria : 1\n",
      "stop leak : 1\n",
      "stop : 1\n",
      "spotted: justin timberlake and ryan gosling : 1\n",
      "sports alert: the toronto raptor : 1\n",
      "sponsor : 1\n",
      "spicer’ : 1\n",
      "spicer tko : 1\n",
      "spicer collects white house staffers' phones in effort : 1\n",
      "sphincter : 1\n",
      "special prosecutor : 1\n",
      "sources: lowry : 1\n",
      "sorry : 1\n",
      "signal and confide : 1\n",
      "shumpert : 1\n",
      "shump : 1\n",
      "shout : 1\n",
      "shame : 1\n",
      "see champion : 1\n",
      "see : 1\n",
      "season 4 : 1\n",
      "sean spicer’s hunt : 1\n",
      "sean spicer; devin nune : 1\n",
      "sean spicer: the president’ : 1\n",
      "sean spicer's staff leaks information : 1\n",
      "sean spicer\" good : 1\n",
      "sean spicer shreds : 1\n",
      "sean spicer on president trump : 1\n",
      "sean spicer on issa : 1\n",
      "sean spicer led first : 1\n",
      "sean spicer in december : 1\n",
      "sean spicer and the white house’ : 1\n",
      "sean spicer \"ivanka : 1\n",
      "seal william “ryan” owen : 1\n",
      "scarlett johansson : 1\n",
      "sarah paulson : 1\n",
      "sally : 1\n",
      "sad \"ralph : 1\n",
      "ryan gosling : 1\n",
      "ruth negga : 1\n",
      "russki : 1\n",
      "russia/trump : 1\n",
      "running : 1\n",
      "rt bleacherreport: kyle lowry : 1\n",
      "royal rumble : 1\n",
      "rolex milgau : 1\n",
      "revealed: sean spicer : 1\n",
      "return : 1\n",
      "representation : 1\n",
      "reports: kyle lowry : 1\n",
      "reporting : 1\n",
      "reported attempt : 1\n",
      "red carpet : 1\n",
      "recap : 1\n",
      "ready : 1\n",
      "raptorsmr: kyle lowry : 1\n",
      "raptors' kyle lowry : 1\n",
      "raptors mt : 1\n",
      "raptors at knick : 1\n",
      "rap : 1\n",
      "raise : 1\n",
      "raceday : 1\n",
      "race : 1\n",
      "putting : 1\n",
      "put on fox : 1\n",
      "public : 1\n",
      "propaganda : 1\n",
      "probably : 1\n",
      "prior : 1\n",
      "pretty : 1\n",
      "press secretary sean spicer : 1\n",
      "president trump : 1\n",
      "president of the academy : 1\n",
      "pr : 1\n",
      "potu : 1\n",
      "post : 1\n",
      "pos liar : 1\n",
      "poc : 1\n",
      "plot : 1\n",
      "pg kyle lowry : 1\n",
      "pg brandon jenning : 1\n",
      "pg : 1\n",
      "personally : 1\n",
      "paging brandon jenning : 1\n",
      "p9 : 1\n",
      "over/under : 1\n",
      "opinion: sean spicer : 1\n",
      "one : 1\n",
      "omg...at : 1\n",
      "octavia : 1\n",
      "obamacare : 1\n",
      "nyt : 1\n",
      "normal : 1\n",
      "nominee : 1\n",
      "no.78 : 1\n",
      "new york : 1\n",
      "need one yesterday : 1\n",
      "near : 1\n",
      "nd : 1\n",
      "nba news : 1\n",
      "nba all-star : 1\n",
      "nba : 1\n",
      "navy sec : 1\n",
      "navy seal : 1\n",
      "nascartalknbc : 1\n",
      "nasa : 1\n",
      "napol : 1\n",
      "muslim oscar : 1\n",
      "msm : 1\n",
      "mr spicer : 1\n",
      "move : 1\n",
      "monster-sponsored : 1\n",
      "monster energy : 1\n",
      "monster (energy : 1\n",
      "monster : 1\n",
      "moment : 1\n",
      "mma : 1\n",
      "missed : 1\n",
      "million : 1\n",
      "miller : 1\n",
      "mike flynn : 1\n",
      "mickey mouse club : 1\n",
      "michael keaton : 1\n",
      "michael jordan : 1\n",
      "mexico : 1\n",
      "metta world peace : 1\n",
      "mellissa : 1\n",
      "melissa mccarthy : 1\n",
      "mcmurray : 1\n",
      "matt damon : 1\n",
      "massive : 1\n",
      "marvel \"red carpet pose : 1\n",
      "march and april : 1\n",
      "mar-a-lago : 1\n",
      "manchester by the sea : 1\n",
      "managed : 1\n",
      "man kyle lowry : 1\n",
      "madonna : 1\n",
      "lying : 1\n",
      "lucy : 1\n",
      "loved : 1\n",
      "love : 1\n",
      "loose : 1\n",
      "lgbt : 1\n",
      "lebanon : 1\n",
      "leaker : 1\n",
      "leaked : 1\n",
      "latest : 1\n",
      "lap 152 : 1\n",
      "kyle : 1\n",
      "kremlin : 1\n",
      "king of gondor : 1\n",
      "kimmel : 1\n",
      "khaled khatib : 1\n",
      "key : 1\n",
      "kellyanne : 1\n",
      "kate hudson at the : 1\n",
      "kate hudson : 1\n",
      "kate beckinsale at the : 1\n",
      "join : 1\n",
      "john : 1\n",
      "janelle : 1\n",
      "jackie chan : 1\n",
      "iran : 1\n",
      "investigation : 1\n",
      "investigate : 1\n",
      "instastory : 1\n",
      "inspection : 1\n",
      "injury : 1\n",
      "incredile : 1\n",
      "imagine : 1\n",
      "hothouse : 1\n",
      "hope : 1\n",
      "hollywood california : 1\n",
      "hollywood : 1\n",
      "hillary : 1\n",
      "hidden figure : 1\n",
      "here’ : 1\n",
      "heartbreaker: kyle lowry : 1\n",
      "hbcu : 1\n",
      "haute couture by riccardo tisci : 1\n",
      "harry : 1\n",
      "hardaway jr : 1\n",
      "happening : 1\n",
      "happened : 1\n",
      "hand : 1\n",
      "hailee steinfeld : 1\n",
      "ha : 1\n",
      "h/t : 1\n",
      "great american race : 1\n",
      "gov : 1\n",
      "gotta : 1\n",
      "got : 1\n",
      "goodyear : 1\n",
      "goodbye : 1\n",
      "golden boot award : 1\n",
      "goid : 1\n",
      "god dammit : 1\n",
      "gmb : 1\n",
      "give : 1\n",
      "get money : 1\n",
      "get : 1\n",
      "germany : 1\n",
      "gene huber : 1\n",
      "gave terrorist : 1\n",
      "game-changer : 1\n",
      "g'nite : 1\n",
      "fun : 1\n",
      "front : 1\n",
      "fraud : 1\n",
      "frantically google : 1\n",
      "frank burn : 1\n",
      "fox30 : 1\n",
      "fos : 1\n",
      "ford fusion : 1\n",
      "following moonlight : 1\n",
      "follow : 1\n",
      "first amendment : 1\n",
      "final : 1\n",
      "fg : 1\n",
      "feb. 26, 2001 : 1\n",
      "faye dunaway : 1\n",
      "faye : 1\n",
      "fantasy team : 1\n",
      "family : 1\n",
      "familiar : 1\n",
      "fair : 1\n",
      "expect : 1\n",
      "events assistant : 1\n",
      "especially : 1\n",
      "era : 1\n",
      "epic : 1\n",
      "enthusiasm : 1\n",
      "elk grove's kyle larson : 1\n",
      "eddie redmayne : 1\n",
      "easter bunny at the white house : 1\n",
      "e1 : 1\n",
      "e-mails of hrc : 1\n",
      "due : 1\n",
      "dude : 1\n",
      "drink : 1\n",
      "don't : 1\n",
      "dollar : 1\n",
      "dolan : 1\n",
      "dj : 1\n",
      "did : 1\n",
      "denzel : 1\n",
      "demand : 1\n",
      "delon and vanvleet : 1\n",
      "delighted : 1\n",
      "delayed streisand effect : 1\n",
      "declining : 1\n",
      "dear : 1\n",
      "daytona : 1\n",
      "dawsonville's chase elliott : 1\n",
      "danica patrick : 1\n",
      "dale jr : 1\n",
      "dale earnhardt : 1\n",
      "daddy : 1\n",
      "curb : 1\n",
      "crystal clarity : 1\n",
      "credit : 1\n",
      "crazy : 1\n",
      "counterpoint : 1\n",
      "cory jo : 1\n",
      "context: 83 : 1\n",
      "congre : 1\n",
      "congratualation : 1\n",
      "confide : 1\n",
      "come : 1\n",
      "collects white house staffers' phones in effort : 1\n",
      "clear : 1\n",
      "cla : 1\n",
      "cia director pompeo : 1\n",
      "chrissy teigen : 1\n",
      "chri : 1\n",
      "chazelle : 1\n",
      "chance : 1\n",
      "celtic : 1\n",
      "celebration : 1\n",
      "carter page and paul manafort : 1\n",
      "canadian : 1\n",
      "canada : 1\n",
      "calvin klein : 1\n",
      "busch's 15th : 1\n",
      "breaking: raptors' kyle lowry : 1\n",
      "breaking: kurt busch : 1\n",
      "breaking update: following : 1\n",
      "breaking : 1\n",
      "bodies....in : 1\n",
      "blame : 1\n",
      "bill owen : 1\n",
      "bg : 1\n",
      "best visual effect : 1\n",
      "best picture actually : 1\n",
      "best original screenplay : 1\n",
      "best director : 1\n",
      "best animated feature : 1\n",
      "benghazi..$7 : 1\n",
      "beautiful : 1\n",
      "barry jenkin : 1\n",
      "b : 1\n",
      "awkward : 1\n",
      "awful : 1\n",
      "awesome : 1\n",
      "award : 1\n",
      "australia : 1\n",
      "asg : 1\n",
      "april ryan : 1\n",
      "ap and time : 1\n",
      "anne frank center : 1\n",
      "and a 2nd : 1\n",
      "american : 1\n",
      "america : 1\n",
      "almost 38 : 1\n",
      "almost : 1\n",
      "all-star game : 1\n",
      "all-star g kyle lowry : 1\n",
      "all-star : 1\n",
      "al qaeda : 1\n",
      "aiming : 1\n",
      "adam schiff : 1\n",
      "academy award best actor : 1\n",
      "academy award : 1\n",
      "9 daytona 500 : 1\n",
      "7.3 rpg : 1\n",
      "7.3 reb : 1\n",
      "4.3 ast : 1\n",
      "4.3 apg : 1\n",
      "4 top 10 : 1\n",
      "37.3 pts : 1\n",
      "37.3 ppg : 1\n",
      "3-pt fg : 1\n",
      "22.8 ppg : 1\n",
      "20:30 and 21:30 : 1\n",
      "2018: tubelight : 1\n",
      "2017: moonlight : 1\n",
      "2017 vanity fair oscar party : 1\n",
      "2017 champion : 1\n",
      "2016: spotlight : 1\n",
      "2/18 bilden : 1\n",
      "16th in the nba : 1\n",
      "Total number of tokens processed: 7183\n",
      "Total number of NEs extracted: 771\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''This is the main module. I am not explicitly writing it as a function as I am not sure what argument you are \n",
    "passing.However you can call this whole cell as a function and it will call the rest of the functions in my module\n",
    "to extract candidates and features\n",
    "'''\n",
    "\n",
    "'''#reads input from the database file and converts to a dataframe. You can change this part accordingly and\n",
    "#directly convert argument tuple to the dataframe'''\n",
    "\n",
    "#Collection.csv\n",
    "df = read_csv('/home/satadisha/Desktop/GitProjects/ELTweetTracker/500Sample.csv', index_col='ID', header=0, encoding='utf-8')\n",
    "#print (df.columns.values.tolist())\n",
    "\n",
    "#%%timeit -o\n",
    "#module_capital_punct.main:\n",
    "'''I am running this for 100 iterations for testing purposes. Of course you no longer need this for loop as you are\n",
    "#running one tuple at a time'''\n",
    "\n",
    "count=0\n",
    "ne_count=0\n",
    "userMention_count=0\n",
    "token_count=0\n",
    "\n",
    "NE_list_phase1=[]\n",
    "UserMention_list=[]\n",
    "\n",
    "#--------------------------------------PHASE I---------------------------------------------------\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    if count<500:\n",
    "        #tweetText=unicode(row['Tweets']).encode('utf-8')\n",
    "        userType=str(row['User Type'])\n",
    "        tweetText=str(row['TweetText'])\n",
    "        #tweetText=row['Tweets']\n",
    "        #print(str(index)+\". \"+userType+\":=>\\n\"+tweetText)\n",
    "        \n",
    "        #capitalization module\n",
    "        #if all words are capitalized:\n",
    "        if tweetText.isupper():\n",
    "            print(\"\",end=\"\")\n",
    "            #print (\"All caps module\\n\")\n",
    "        elif tweetText.islower():\n",
    "            print(\"\",end=\"\")\n",
    "            #print (\"All lower module\\n\")\n",
    "        else:\n",
    "            ne_List_final=[]\n",
    "            userMention_List_final=[]\n",
    "            #pre-modification: returns word list split at whitespaces; retains punctuation\n",
    "            tweetSentences=list(filter (lambda sentence: len(sentence)>0, tweetText.split('\\n')))\n",
    "            tweetSentenceList=flatten(list(map(lambda sentText: sent_tokenize(sentText.lstrip().rstrip()),tweetSentences)),[])\n",
    "            \n",
    "            #printList(tweetSentenceList)\n",
    "            for sentence in tweetSentenceList:\n",
    "                tweetWordList= sentence.split()\n",
    "                \n",
    "                token_count+=len(tweetWordList)\n",
    "                #print (tweetWordList)\n",
    "                #returns position of words that are capitalized\n",
    "                tweetWordList_cappos = list(map(lambda element : element[0], filter(lambda element : capCheck(element[1]), enumerate(tweetWordList))))\n",
    "                \n",
    "                #returns list of @userMentions\n",
    "                userMentionswPunct=list(filter(lambda phrase: phrase.startswith('@'), tweetWordList))\n",
    "                userMentions=list(map(lambda mention: mention.rstrip(string.punctuation), userMentionswPunct))\n",
    "                \n",
    "                #non @usermentions are processed in this function to find non @, non hashtag Entities\n",
    "                ne_List_allCheck= trueEntity_process(tweetWordList_cappos,tweetWordList)\n",
    "                \n",
    "                #function to process and store @ user mentions\n",
    "                \n",
    "                ne_count+=len(ne_List_allCheck)\n",
    "                userMention_count+=len(userMentions)\n",
    "                \n",
    "                ne_List_final+=ne_List_allCheck\n",
    "                userMention_List_final+=userMentions\n",
    "                \n",
    "            #insert_dict ((mention.phraseText.lstrip(string.punctuation)).rstrip(string.punctuation).strip()).lower()\n",
    "            for candidate in ne_List_final:\n",
    "                insert_dict ((((candidate.phraseText.lstrip(string.punctuation)).rstrip(string.punctuation)).rstrip(\"'s\").strip()).lower())\n",
    "            #printList(ne_List_final)\n",
    "            '''if(userMention_List_final):\n",
    "                print(userMention_List_final)\n",
    "            \n",
    "            NE_list_phase1+=ne_List_final\n",
    "            UserMention_list+=userMention_List_final\n",
    "            print (\"\\n\")'''\n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "sorted_d = [(k,v) for v,k in sorted([(v,k) for k,v in NE_container.items()],reverse=True)]\n",
    "for key, value in sorted_d:\n",
    "    #print(\"=>\")\n",
    "    print (key+\" : \"+str(value))\n",
    "\n",
    "print(\"Total number of tokens processed: \"+str(token_count))\n",
    "print (\"Total number of NEs extracted: \"+str(ne_count))\n",
    "#--------------------------------------PHASE I---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#word=\"hahaha\"\n",
    "text=\"POS LIAR\"\n",
    "print(text.isupper())\n",
    "phrase=(text.lstrip(string.punctuation)).rstrip(string.punctuation).strip()\n",
    "#p1= re.compile(r'[A-Z]*\\s*[A-Z]{2,}[^A-Za-z]*\\s*[A-Za-z]+')\n",
    "p1= re.compile(r'[A-Z]*\\s*[A-Z]{4,}[^A-Za-z]*\\s*[A-Za-z]+')\n",
    "match_lst = p1.findall(phrase)\n",
    "if match_lst:\n",
    "    if not phrase.isupper():\n",
    "        print (\"GOTIT: \"+phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
