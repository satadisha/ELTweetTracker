{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from pandas import read_csv, DataFrame\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from collections import Iterable, OrderedDict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import stats\n",
    "import NE_candidate_module as ne\n",
    "import NE_candidate_module as ne\n",
    "import Mention\n",
    "import threading, queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------Existing Lists--------------------\n",
    "cachedStopWords = set(stopwords.words(\"english\"))\n",
    "cachedStopWords.update((\"and\",\"make\",\"oh\",\"via\",\"i\",\"i'll\",\"don't\",\"would\",\"should\",\"shall\",\"hasn't\",\"wasn't\",\"wasn’t\",\"also\",\"let's\",\"let\",\"well\",\"just\",\"someone\",\"theres\",\"somebody\",\"didn't\",\"i've\",\"they're\",\"we're\",\"we'll\",\"we've\",\"they've\",\"they'd\",\"they'll\",\"again\",\"you're\",\"thats\",\"that's\",\"i'm\",\"a\",\"so\",\"except\",\"arn't\",\"aren't\",\"arent\",\"this\",\"when\",\"it\",\"it's\",\"he's\",\"she's\",\"she'd\",\"he'd\",\"he'll\",\"she'll\",\"many\",\"can't\",\"even\",\"cant\",\"yes\",\"no\",\"these\",\"here\",\"there\",\"to\",\"may\",\"maybe\",\"<hashtag>\",\"<hashtag>.\",\"ever\",\"every\",\"never\",\"there's\",\"there’s\"))\n",
    "cachedTitles = [\"Mr.\",\"Mr\",\"Mrs.\",\"Mrs\",\"Miss\",\"Ms\",\"Sen.\"]\n",
    "prep_list=[\"in\",\"at\",\"of\",\"on\",\"and\",\"by\"] #includes common conjunction as well\n",
    "article_list=[\"a\",\"an\",\"the\"]\n",
    "day_list=[\"sunday\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"mon\",\"tues\",\"wed\",\"thurs\",\"fri\",\"sat\",\"sun\"]\n",
    "month_list=[\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\",\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "chat_word_list=[\"thank\",\"thanks\",\"congrats\",\"whoa\",\"hey\",\"hi\",\"huh\",\"fyi\",\"duh\",\"damn\",\"lol\",\"omg\",\"congratulations\",\"fuck\",\"wtf\",\"wtaf\",\"xoxo\",\"rofl\",\"imo\",\"wow\",\"fck\",\"haha\",\"hehe\",\"hoho\"]\n",
    "#---------------------Existing Lists--------------------\n",
    "NE_container={}\n",
    "\n",
    "def insert_dict(candidate):\n",
    "    key=(((candidate.phraseText.lstrip(string.punctuation)).rstrip(string.punctuation)).replace(\"'s\",\"\").replace(\"’s\",\"\").replace(\"’s\",\"\").strip()).lower()\n",
    "    if key in NE_container:\n",
    "        NE_container[key] += 1\n",
    "    else:\n",
    "        NE_container[key] = 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printList(mylist):\n",
    "    print(\"[\"),\n",
    "    #print \"[\",\n",
    "    for item in mylist:\n",
    "        if item != None:\n",
    "            if isinstance(item,ne.NE_candidate):\n",
    "                item.print_obj()\n",
    "                #print (item.phraseText)\n",
    "            else:\n",
    "                print (item+\",\", end=\"\")\n",
    "                #print item+\",\",\n",
    "    #print \"]\"\n",
    "    print(\"]\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(mylist, outlist,ignore_types=(str, bytes, ne.NE_candidate)):\n",
    "    \n",
    "    if mylist !=[]:\n",
    "        for item in mylist:\n",
    "            #print not isinstance(item, ne.NE_candidate)\n",
    "            if isinstance(item, list) and not isinstance(item, ignore_types):\n",
    "                flatten(item, outlist)\n",
    "            else:\n",
    "                if isinstance(item,ne.NE_candidate):\n",
    "                    item.phraseText=item.phraseText.strip(' \\t\\n\\r')\n",
    "                    item.reset_length()\n",
    "                else:\n",
    "                    item=item.strip(' \\t\\n\\r')\n",
    "                outlist.append(item)\n",
    "    return outlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consecutive_cap(tweetWordList_cappos,tweetWordList):\n",
    "    output=[]\n",
    "    #identifies consecutive numbers in the sequence\n",
    "    for k, g in groupby(enumerate(tweetWordList_cappos), lambda element: element[0]-element[1]):\n",
    "        output.append(list(map(itemgetter(1), g)))\n",
    "    count=0\n",
    "    if output:        \n",
    "        final_output=[output[0]]\n",
    "        for first, second in (zip(output,output[1:])):\n",
    "            if ((second[0]-first[-1])==2) & (tweetWordList[first[-1]+1].lower() in prep_list):\n",
    "                (final_output[-1]).extend([first[-1]+1]+second)\n",
    "            elif((second[0]-first[-1])==3) & (tweetWordList[first[-1]+1].lower() in prep_list)& (tweetWordList[first[-1]+2].lower() in article_list):\n",
    "                (final_output[-1]).extend([first[-1]+1]+[first[-1]+2]+second)\n",
    "            else:\n",
    "                final_output.append(second)\n",
    "                #merge_positions.append(False)\n",
    "    else:\n",
    "        final_output=[]\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#basically splitting the original NE_candidate text and building individual object from each text snippet\n",
    "def build_custom_NE(phrase,pos,prototype,feature_index,feature_value):\n",
    "    #print(\"Enters\")\n",
    "    position=pos\n",
    "    custom_NE= ne.NE_candidate(phrase,position)\n",
    "    for i in range(14):\n",
    "        custom_NE.set_feature(i,prototype.features[i])\n",
    "    custom_NE.set_feature(feature_index,feature_value)\n",
    "    if (feature_index== ne.is_csl) & (feature_value== True):\n",
    "        custom_NE.set_feature(ne.start_of_sentence, False)\n",
    "    custom_NE=entity_info_check(custom_NE)\n",
    "    return custom_NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abbrv_algo(ne_element):\n",
    "    '''abbreviation algorithm \n",
    "    trailing apostrophe:\n",
    "           |period:\n",
    "           |     multiple letter-period sequence:\n",
    "           |         all caps\n",
    "           | non period:\n",
    "           |     ?/! else drop apostrophe\n",
    "    else:\n",
    "        unchanged\n",
    "    '''\n",
    "    phrase= ne_element.phraseText\n",
    "    #print(\"=>\"+phrase)\n",
    "    #since no further split occurs we can set remaining features now\n",
    "    ne_element.set_feature(ne.capitalized, True)\n",
    "    if ne_element.phraseText.isupper():\n",
    "        ne_element.set_feature(ne.all_capitalized, True)\n",
    "    else:\n",
    "        ne_element.set_feature(ne.all_capitalized, False)\n",
    "        \n",
    "    abbreviation_flag=False\n",
    "    p=re.compile(r'[^a-zA-Z\\d\\s]$')\n",
    "    match_list = p.findall(phrase)\n",
    "    if len(match_list)>0:\n",
    "        #print(\"Here\")\n",
    "        if phrase.endswith('.'):\n",
    "            p1= re.compile(r'([a-zA-Z][\\.]\\s*)')\n",
    "            match_list = p1.findall(phrase)\n",
    "            if ((len(match_list)>1) & (len(phrase)<6)):\n",
    "                #print (\"1. Found abbreviation: \"+phrase)\n",
    "                abbreviation_flag= True\n",
    "            else:\n",
    "                phrase= phrase[:-1]\n",
    "        else:\n",
    "            phrase= phrase[:-1]\n",
    "            #if not (phrase.endswith('?')|phrase.endswith('!')|phrase.endswith(')')|phrase.endswith('>')):\n",
    "                #phrase= phrase[:-1]\n",
    "    else:\n",
    "        p2=re.compile(r'([^a-zA-Z0-9_\\s])')\n",
    "        match_list = p2.findall(phrase)\n",
    "        if ((len(match_list)==0) & (phrase.isupper()) & (len(phrase)<7)& (len(phrase)>1)):\n",
    "            #print (\"2. Found abbreviation!!: \"+phrase)\n",
    "            abbreviation_flag= True\n",
    "        else:\n",
    "            #print(\"Here-> \"+phrase)\n",
    "            p3= re.compile(r'([A-Z][.][A-Z])')\n",
    "            p4= re.compile(r'\\s')\n",
    "            match_list = p3.findall(phrase)\n",
    "            match_list1 = p4.findall(phrase)\n",
    "            if ((len(match_list)>0) & (len(match_list1)==0)):\n",
    "                abbreviation_flag= True\n",
    "                print (\"3. Found abbreviation!!: \"+phrase)\n",
    "            \n",
    "    #element= ne.NE_candidate(phrase.strip())\n",
    "    ne_element.phraseText=phrase\n",
    "    ne_element.reset_length()\n",
    "    ne_element.set_feature(ne.abbreviation, abbreviation_flag)\n",
    "    return ne_element\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def punct_clause(NE_phrase_in):\n",
    "    \n",
    "    NE_phrases=entity_info_check(NE_phrase_in)\n",
    "    cap_phrases=NE_phrases.phraseText.strip()\n",
    "    #print (cap_phrases)\n",
    "    if (re.compile(r'[^a-zA-Z0-9_\\s]')).findall(cap_phrases):\n",
    "        #case of intermediate punctuations: handles abbreviations\n",
    "        p1= re.compile(r'(?:[a-zA-Z0-9][^a-zA-Z0-9_\\s]\\s*)')\n",
    "        match_lst = p1.findall(cap_phrases)\n",
    "        if match_lst:\n",
    "            index= (list( p1.finditer(cap_phrases) )[-1]).span()[1]\n",
    "        \n",
    "        p= re.compile(r'[^a-zA-Z\\d\\s]')\n",
    "        match_list = p.findall(cap_phrases)\n",
    "\n",
    "        p2=re.compile(r'[^a-zA-Z\\d\\s]$') #ends with punctuation\n",
    "\n",
    "        if len(match_list)-len(match_lst)>0:\n",
    "            if (p2.findall(cap_phrases)):\n",
    "                #only strips trailing punctuations, not intermediate ones following letters\n",
    "                cap_phrases = cap_phrases[0:index]+re.sub(p, '', cap_phrases[index:])\n",
    "                NE_phrases.phraseText= cap_phrases\n",
    "        \n",
    "    \n",
    "    #comma separated NEs\n",
    "    #lst=filter(lambda(word): word!=\"\", re.split('[,]', cap_phrases))\n",
    "    start_of_sentence_fix=NE_phrases.features[ne.start_of_sentence]\n",
    "    wordlst=list(filter(lambda word: word!=\"\", re.split('[,]', cap_phrases)))\n",
    "    if (NE_phrases.features[ne.date_indicator]==False) & (len(wordlst)>1):\n",
    "        pos=NE_phrases.position\n",
    "        combined=[]\n",
    "        prev=0\n",
    "        for i in range(len(wordlst)):\n",
    "            word=wordlst[i]\n",
    "            word_len=len(list(filter(lambda individual_word: individual_word!=\"\", re.split('[ ]', word))))\n",
    "            word_pos=pos[(prev):(prev+word_len)]\n",
    "            prev=prev+word_len\n",
    "            combined+=[[word]+word_pos]\n",
    "        \n",
    "        lst_nsw=list(filter(lambda element: (((str(element[0])).lower() not in cachedStopWords) & (len(str(element[0]))>1)) ,combined))\n",
    "        #print (lst_nsw)\n",
    "        final_lst= list(map(lambda element:build_custom_NE(str(element[0]),element[1:],NE_phrases,ne.is_csl,True), lst_nsw))\n",
    "        final_lst[0].set_feature(ne.start_of_sentence, NE_phrases.features[ne.start_of_sentence])\n",
    "    else:\n",
    "        NE_phrases.set_feature(ne.is_csl,False)\n",
    "        final_lst=[NE_phrases]\n",
    "    \n",
    "    #check abbreviation\n",
    "    final_lst= list(map(lambda phrase: abbrv_algo(phrase), final_lst))\n",
    "\n",
    "    \n",
    "    #print(lst)\n",
    "    return final_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -o\n",
    "def f(x,tweetWordList):\n",
    "\n",
    "    #list1=map(lambda word: check(tweetWordList[word], word), x)\n",
    "    list1=list(map(lambda word: tweetWordList[word]+\" \", x[:-1]))\n",
    "    phrase=\"\".join(list1)+tweetWordList[x[-1]]\n",
    "\n",
    "    if not ((phrase[0].isdigit()) & (len(x)==1)):\n",
    "        NE_phrase= ne.NE_candidate(phrase.strip(),x)\n",
    "        if 0 in x:\n",
    "            NE_phrase.set_feature(ne.start_of_sentence,True)\n",
    "        else:\n",
    "            NE_phrase.set_feature(ne.start_of_sentence,False)\n",
    "    else:\n",
    "        NE_phrase= ne.NE_candidate(\"JUST_DIGIT_ERROR\",[])\n",
    "\n",
    "    return NE_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def capCheck(word):\n",
    "    combined_list=[]+list(cachedStopWords)+prep_list+chat_word_list\n",
    "    if word.startswith('@'):\n",
    "        return False\n",
    "    elif \"<Hashtag\" in word:\n",
    "        return False\n",
    "    elif ((word.lstrip(string.punctuation)).rstrip(string.punctuation)).lower() in combined_list:\n",
    "        if(word!=\"The\"):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    elif word[0].isdigit():\n",
    "        return True\n",
    "    else:\n",
    "        p=re.compile(r'^[\\W]*[A-Z]')\n",
    "        l= p.match(word)\n",
    "        if l:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_check(ne_phrase):\n",
    "    title_flag=False\n",
    "    words=ne_phrase.phraseText.split()\n",
    "    for word in words:\n",
    "        if word in cachedTitles:\n",
    "            title_flag= True\n",
    "            break\n",
    "    ne_phrase.set_feature(ne.title,title_flag)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entity_info_check(ne_phrase):\n",
    "    flag1=False #has number\n",
    "    flag3=False\n",
    "    flag_ind=[] #is number\n",
    "    month_ind=[]\n",
    "    date_num_holder=[]\n",
    "    words=ne_phrase.phraseText.split()\n",
    "    for word in words:\n",
    "        word=(word.strip()).rstrip(string.punctuation).lower()\n",
    "        if not word.isalpha():\n",
    "            flag_ind+=[True]\n",
    "            if word.isdigit():\n",
    "                date_num_holder+=['num']\n",
    "            else:\n",
    "                date_num_holder+=['alpha']\n",
    "        else:\n",
    "            flag_ind+=[False]\n",
    "            if word in month_list:\n",
    "                month_ind+=[True]\n",
    "                date_num_holder+=['month']\n",
    "            elif word in day_list:\n",
    "                date_num_holder+=['day']\n",
    "            elif word in prep_list:\n",
    "                date_num_holder+=['preposition']\n",
    "            elif word in article_list:\n",
    "                date_num_holder+=['article']\n",
    "            else:\n",
    "                #print(\"=>\"+word)\n",
    "                date_num_holder+=['string']\n",
    "    if True in flag_ind:\n",
    "        flag1=True\n",
    "    if True in month_ind:\n",
    "        flag3=True\n",
    "    ne_phrase.set_feature(ne.has_number,flag1)\n",
    "    ne_phrase.set_feature(ne.date_indicator,flag3)\n",
    "    ne_phrase.set_date_num_holder(date_num_holder)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#removing commonly used expletives, enunciated chat words and other common words (like days of the week, common expressions)\n",
    "def slang_remove(ne_phrase):\n",
    "    phrase=(ne_phrase.phraseText.strip()).rstrip(string.punctuation).lower()\n",
    "    p1= re.compile(r'([A-Za-z]+)\\1\\1{1,}')\n",
    "    match_lst = p1.findall(phrase)\n",
    "    if phrase in article_list:\n",
    "        return True\n",
    "    elif phrase in day_list:\n",
    "        return True\n",
    "    elif phrase in month_list:\n",
    "        return True\n",
    "    elif match_lst:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apostrope_check(ne_phrase):\n",
    "    apostrophe=\"'s\"\n",
    "    bad_apostrophe=\"’s\"\n",
    "    phrase=(ne_phrase.phraseText.strip()).rstrip(string.punctuation).lower()\n",
    "    if ((apostrophe in phrase) |(bad_apostrophe in phrase)):\n",
    "        if phrase.endswith(apostrophe):\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,0)\n",
    "        else:\n",
    "            #print(phrase.find(apostrophe))\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,phrase.find(apostrophe))\n",
    "\n",
    "        if phrase.endswith(bad_apostrophe):\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,0)\n",
    "        else:\n",
    "            #print(phrase.find(apostrophe))\n",
    "            ne_phrase.set_feature(ne.is_apostrophed,phrase.find(bad_apostrophe))\n",
    "    else:\n",
    "        ne_phrase.set_feature(ne.is_apostrophed,-1)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def punctuation_check(ne_phrase):\n",
    "    holder=[]\n",
    "    punctuation_holder=[]\n",
    "    flag_holder=[]\n",
    "    phrase=(ne_phrase.phraseText.strip()).rstrip(string.punctuation).lower()\n",
    "    for i in range(len(phrase)):\n",
    "        if (phrase[i] in string.punctuation):\n",
    "            holder+=[i]\n",
    "    for i in holder:\n",
    "        if ((i<(len(phrase)-1)) & (phrase[i]==\"'\") & (phrase[i+1]==\"s\")):\n",
    "            flag_holder+=[False]\n",
    "        elif ((i==(len(phrase)-1)) & (phrase[i]==\"'\")):\n",
    "            flag_holder+=[False]\n",
    "        else:\n",
    "            flag_holder+=[True]\n",
    "            punctuation_holder+=[i]\n",
    "    #print(flag_holder)\n",
    "    ne_phrase.set_punctuation_holder(punctuation_holder)\n",
    "    if True in flag_holder:\n",
    "        ne_phrase.set_feature(ne.has_intermediate_punctuation,True)\n",
    "    else:\n",
    "        ne_phrase.set_feature(ne.has_intermediate_punctuation,False)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tense_check(ne_phrase):\n",
    "    words=(((ne_phrase.phraseText.strip()).rstrip(string.punctuation)).lower()).split()\n",
    "    verb_flag=False\n",
    "    adverb_flag=False\n",
    "    if (len(words)==1):\n",
    "        if words[0].endswith(\"ing\"):\n",
    "            verb_flag=True\n",
    "        if words[0].endswith(\"ly\"):\n",
    "            adverb_flag=True\n",
    "    ne_phrase.set_feature(ne.ends_like_verb,verb_flag)\n",
    "    ne_phrase.set_feature(ne.ends_like_adverb,adverb_flag)\n",
    "    return ne_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def capitalization_change(ne_element):\n",
    "    phrase=((ne_element.phraseText.lstrip(string.punctuation)).rstrip(string.punctuation)).strip()\n",
    "    val=-1\n",
    "    topic_indicator=False\n",
    "    p1= re.compile(r'[A-Z]*\\s*[A-Z]{4,}[^A-Za-z]*\\s+[A-Za-z]+') #BREAKING: Toronto Raptors\n",
    "    p2= re.compile(r'([A-Z]{1}[a-z]+)+[^A-Za-z]*\\s+[A-Z]{4,}') #The DREAMIEST LAND\n",
    "    match_lst1 = p1.findall(phrase)\n",
    "    match_lst2 = p2.findall(phrase)\n",
    "    if (match_lst1):\n",
    "        if not phrase.isupper():\n",
    "            p3=re.compile(r'[A-Z]*\\s*[A-Z]{4,}[^A-Za-z]*\\s+')\n",
    "            val=list(p3.finditer(phrase))[-1].span()[1]\n",
    "            if(\":\" in phrase):\n",
    "                topic_indicator=True\n",
    "            ne_element.set_feature(ne.change_in_capitalization,val)\n",
    "    elif (match_lst2):\n",
    "        #print (\"GOTIT2: \"+phrase)\n",
    "        p3=re.compile(r'([A-Z]{1}[a-z]+)+')\n",
    "        val=list(p3.finditer(phrase))[-1].span()[1]\n",
    "        ne_element.set_feature(ne.change_in_capitalization,val)\n",
    "    else:\n",
    "        ne_element.set_feature(ne.change_in_capitalization,val)\n",
    "    ne_element.set_feature(ne.has_topic_indicator,topic_indicator)\n",
    "    return ne_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trueEntity_process(tweetWordList_cappos,tweetWordList,q):\n",
    "    \n",
    "    #returns list with position of consecutively capitalized words\n",
    "    output = consecutive_cap(tweetWordList_cappos,tweetWordList)\n",
    "\n",
    "    #consecutive capitalized phrases \n",
    "    consecutive_cap_phrases1=list(map(lambda x: f(x,tweetWordList), output))\n",
    "\n",
    "    consecutive_cap_phrases=list(filter(lambda candidate:(candidate.phraseText!=\"JUST_DIGIT_ERROR\"),consecutive_cap_phrases1))\n",
    "\n",
    "    \n",
    "    #implement the punctuation clause\n",
    "    ne_List_pc=flatten(list(map(lambda NE_phrase: punct_clause(NE_phrase), consecutive_cap_phrases)),[])\n",
    "    \n",
    "\n",
    "    #implement title detection\n",
    "    ne_List_titleCheck= list(map(lambda element: title_check(element), ne_List_pc))\n",
    "    \n",
    "    #implement slang check and remove\n",
    "    ne_List_slangCheck= list(filter(lambda element: not slang_remove(element), ne_List_titleCheck))\n",
    "    \n",
    "    #implement apostrophe, tense and punctuation marker with final number check\n",
    "    ne_List_apostropeCheck= list(map(lambda element: apostrope_check(element), ne_List_slangCheck))\n",
    "    ne_List_punctuationCheck= list(map(lambda element: punctuation_check(element), ne_List_apostropeCheck))\n",
    "    ne_List_numCheck=list(filter(lambda candidate: not (candidate.phraseText.lstrip(string.punctuation).rstrip(string.punctuation).strip()).isdigit(), ne_List_punctuationCheck))\n",
    "    ne_List_tenseCheck= list(map(lambda element: tense_check(element), ne_List_numCheck))\n",
    "    \n",
    "    #tracking sudden change in capitalization pattern\n",
    "    ne_List_allCheck= list(map(lambda element: capitalization_change(element), ne_List_tenseCheck))\n",
    "    q.put(ne_List_allCheck)\n",
    "    \n",
    "    #return ne_List_allCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sean spicer : [62, '15.0347890176']\n",
      "kyle lowry : [58, '14.0389071413']\n",
      "kurt busch : [16, '3.58214744064']\n",
      "trump : [11, '2.33729509532']\n",
      "white house : [10, '2.08832462625']\n",
      "spicer : [9, '1.83935415719']\n",
      "moonlight : [9, '1.83935415719']\n",
      "best picture : [8, '1.59038368813']\n",
      "russia : [7, '1.34141321906']\n",
      "raptors : [7, '1.34141321906']\n",
      "oscar : [6, '1.09244275']\n",
      "la la land : [6, '1.09244275']\n",
      "aim : [6, '1.09244275']\n",
      "knicks : [5, '0.843472280937']\n",
      "nascar : [5, '0.843472280937']\n",
      "russian : [4, '0.594501811873']\n",
      "kurt : [4, '0.594501811873']\n",
      "daytona 500 : [4, '0.594501811873']\n",
      "breaking: raptors : [4, '0.594501811873']\n",
      "live : [4, '0.594501811873']\n",
      "rt : [3, '0.345531342809']\n",
      "here : [3, '0.345531342809']\n",
      "lowry : [3, '0.345531342809']\n",
      "sean : [3, '0.345531342809']\n",
      "mahershala ali : [3, '0.345531342809']\n",
      "cbs : [3, '0.345531342809']\n",
      "cia : [3, '0.345531342809']\n",
      "muslim : [3, '0.345531342809']\n",
      "the raptors : [3, '0.345531342809']\n",
      "really : [3, '0.345531342809']\n",
      "pathological liar sean spicer : [3, '0.345531342809']\n",
      "yemen : [3, '0.345531342809']\n",
      "breaking: kyle lowry : [3, '0.345531342809']\n",
      "toronto : [3, '0.345531342809']\n",
      "east : [3, '0.345531342809']\n",
      "dale earnhardt jr : [2, '0.0965608737458']\n",
      "tv : [2, '0.0965608737458']\n",
      "stay : [2, '0.0965608737458']\n",
      "id : [2, '0.0965608737458']\n",
      "remember : [2, '0.0965608737458']\n",
      "all-star kyle lowry : [2, '0.0965608737458']\n",
      "best actress : [2, '0.0965608737458']\n",
      "donald trump : [2, '0.0965608737458']\n",
      "damien chazelle : [2, '0.0965608737458']\n",
      "find leakers : [2, '0.0965608737458']\n",
      "best : [2, '0.0965608737458']\n",
      "casey affleck : [2, '0.0965608737458']\n",
      "good : [2, '0.0965608737458']\n",
      "snl : [2, '0.0965608737458']\n",
      "oscars : [2, '0.0965608737458']\n",
      "sean spicer \"donald trump : [2, '0.0965608737458']\n",
      "the white helmets : [2, '0.0965608737458']\n",
      "great : [2, '0.0965608737458']\n",
      "huge : [2, '0.0965608737458']\n",
      "51.4 fg : [2, '0.0965608737458']\n",
      "steve harvey : [2, '0.0965608737458']\n",
      "busch : [2, '0.0965608737458']\n",
      "keep : [2, '0.0965608737458']\n",
      "playoffs : [2, '0.0965608737458']\n",
      "97.4 ft : [2, '0.0965608737458']\n",
      "president : [2, '0.0965608737458']\n",
      "gop : [2, '0.0965608737458']\n",
      "benghazi : [2, '0.0965608737458']\n",
      "demar derozan : [2, '0.0965608737458']\n",
      "ford : [2, '0.0965608737458']\n",
      "warren beatty : [2, '0.0965608737458']\n",
      "big : [2, '0.0965608737458']\n",
      "sean sphincter : [2, '0.0965608737458']\n",
      "emma stone : [2, '0.0965608737458']\n",
      "news : [2, '0.0965608737458']\n",
      "kyle busch : [2, '0.0965608737458']\n",
      "last : [2, '0.0965608737458']\n",
      "join : [1, '-0.152409595318']\n",
      "b : [1, '-0.152409595318']\n",
      "kremlin : [1, '-0.152409595318']\n",
      "loose : [1, '-0.152409595318']\n",
      "nascartalknbc : [1, '-0.152409595318']\n",
      "sean spicer led first : [1, '-0.152409595318']\n",
      "update : [1, '-0.152409595318']\n",
      "trump and xi talked : [1, '-0.152409595318']\n",
      "iran : [1, '-0.152409595318']\n",
      "carter page and paul manafort : [1, '-0.152409595318']\n",
      "class : [1, '-0.152409595318']\n",
      "bg : [1, '-0.152409595318']\n",
      "ids : [1, '-0.152409595318']\n",
      "time : [1, '-0.152409595318']\n",
      "whitehouse press secretary sean spicer : [1, '-0.152409595318']\n",
      "obamacare : [1, '-0.152409595318']\n",
      "syria : [1, '-0.152409595318']\n",
      "gov : [1, '-0.152409595318']\n",
      "sean spicer staff leaks information : [1, '-0.152409595318']\n",
      "hollywood california : [1, '-0.152409595318']\n",
      "hothouse : [1, '-0.152409595318']\n",
      "haute couture by riccardo tisci : [1, '-0.152409595318']\n",
      "pos liar : [1, '-0.152409595318']\n",
      "germany : [1, '-0.152409595318']\n",
      "sean spicer; devin nunes : [1, '-0.152409595318']\n",
      "come : [1, '-0.152409595318']\n",
      "special prosecutor : [1, '-0.152409595318']\n",
      "and a 2nd : [1, '-0.152409595318']\n",
      "delon and vanvleet : [1, '-0.152409595318']\n",
      "whitehouse : [1, '-0.152409595318']\n",
      "red carpet : [1, '-0.152409595318']\n",
      "imagine : [1, '-0.152409595318']\n",
      "events assistant : [1, '-0.152409595318']\n",
      "america : [1, '-0.152409595318']\n",
      "pretty : [1, '-0.152409595318']\n",
      "john : [1, '-0.152409595318']\n",
      "goodyear : [1, '-0.152409595318']\n",
      "plot : [1, '-0.152409595318']\n",
      "monster (energy : [1, '-0.152409595318']\n",
      "fantasy team : [1, '-0.152409595318']\n",
      "trumps : [1, '-0.152409595318']\n",
      "wsj and wapost : [1, '-0.152409595318']\n",
      "daytona : [1, '-0.152409595318']\n",
      "personally : [1, '-0.152409595318']\n",
      "pg brandon jennings : [1, '-0.152409595318']\n",
      "president of the academy : [1, '-0.152409595318']\n",
      "nyt : [1, '-0.152409595318']\n",
      "dale earnhardt : [1, '-0.152409595318']\n",
      "one : [1, '-0.152409595318']\n",
      "nba : [1, '-0.152409595318']\n",
      "faye dunaway : [1, '-0.152409595318']\n",
      "declining : [1, '-0.152409595318']\n",
      "finals : [1, '-0.152409595318']\n",
      "chazelle : [1, '-0.152409595318']\n",
      "the washington post : [1, '-0.152409595318']\n",
      "napol : [1, '-0.152409595318']\n",
      "awful : [1, '-0.152409595318']\n",
      "msm : [1, '-0.152409595318']\n",
      "4 top 10s : [1, '-0.152409595318']\n",
      "al qaeda : [1, '-0.152409595318']\n",
      "fos : [1, '-0.152409595318']\n",
      "hardaway jr : [1, '-0.152409595318']\n",
      "crazy : [1, '-0.152409595318']\n",
      "breaking: kurt busch : [1, '-0.152409595318']\n",
      "shame : [1, '-0.152409595318']\n",
      "celebration : [1, '-0.152409595318']\n",
      "new : [1, '-0.152409595318']\n",
      "throwback : [1, '-0.152409595318']\n",
      "australia : [1, '-0.152409595318']\n",
      "navy seal : [1, '-0.152409595318']\n",
      "academy award best actor : [1, '-0.152409595318']\n",
      "counterpoint : [1, '-0.152409595318']\n",
      "elk grove kyle larson : [1, '-0.152409595318']\n",
      "dj : [1, '-0.152409595318']\n",
      "press secretary sean spicer : [1, '-0.152409595318']\n",
      "7.3 rpg : [1, '-0.152409595318']\n",
      "sponsors : [1, '-0.152409595318']\n",
      "pg kyle lowry : [1, '-0.152409595318']\n",
      "fox30 : [1, '-0.152409595318']\n",
      "opinion: sean spicer : [1, '-0.152409595318']\n",
      "crystal clarity : [1, '-0.152409595318']\n",
      "instastory : [1, '-0.152409595318']\n",
      "uber svp : [1, '-0.152409595318']\n",
      "daddy : [1, '-0.152409595318']\n",
      "e1 : [1, '-0.152409595318']\n",
      "sean spicer on issa : [1, '-0.152409595318']\n",
      "monster-sponsored : [1, '-0.152409595318']\n",
      "frank burns : [1, '-0.152409595318']\n",
      "nba all-star : [1, '-0.152409595318']\n",
      "incredile : [1, '-0.152409595318']\n",
      "welcome drose : [1, '-0.152409595318']\n",
      "warren : [1, '-0.152409595318']\n",
      "winner : [1, '-0.152409595318']\n",
      "spicer tko : [1, '-0.152409595318']\n",
      "adam schiffs : [1, '-0.152409595318']\n",
      "spotted: justin timberlake and ryan gosling : [1, '-0.152409595318']\n",
      "injury : [1, '-0.152409595318']\n",
      "tune : [1, '-0.152409595318']\n",
      "octavia : [1, '-0.152409595318']\n",
      "say : [1, '-0.152409595318']\n",
      "melissa mccarthy : [1, '-0.152409595318']\n",
      "shump : [1, '-0.152409595318']\n",
      "raptorsmr: kyle lowry : [1, '-0.152409595318']\n",
      "gmb : [1, '-0.152409595318']\n",
      "navy sec : [1, '-0.152409595318']\n",
      "moment : [1, '-0.152409595318']\n",
      "best animated feature : [1, '-0.152409595318']\n",
      "raptors mt : [1, '-0.152409595318']\n",
      "drink : [1, '-0.152409595318']\n",
      "scarlett johansson : [1, '-0.152409595318']\n",
      "rt bleacherreport: kyle lowry : [1, '-0.152409595318']\n",
      "season 4 : [1, '-0.152409595318']\n",
      "tim tebow : [1, '-0.152409595318']\n",
      "kyle : [1, '-0.152409595318']\n",
      "monster : [1, '-0.152409595318']\n",
      "west wing “leak crackdown : [1, '-0.152409595318']\n",
      "millions : [1, '-0.152409595318']\n",
      "propaganda : [1, '-0.152409595318']\n",
      "prior : [1, '-0.152409595318']\n",
      "president trump : [1, '-0.152409595318']\n",
      "pr : [1, '-0.152409595318']\n",
      "beautiful : [1, '-0.152409595318']\n",
      "the right scoop : [1, '-0.152409595318']\n",
      "seal william “ryan” owens : [1, '-0.152409595318']\n",
      "trying : [1, '-0.152409595318']\n",
      "tune-in : [1, '-0.152409595318']\n",
      "sean spicer and the white house : [1, '-0.152409595318']\n",
      "ap and time : [1, '-0.152409595318']\n",
      "normal : [1, '-0.152409595318']\n",
      "hidden figures : [1, '-0.152409595318']\n",
      "dude : [1, '-0.152409595318']\n",
      "2017 vanity fair oscar party : [1, '-0.152409595318']\n",
      "unfortunately : [1, '-0.152409595318']\n",
      "running : [1, '-0.152409595318']\n",
      "fg : [1, '-0.152409595318']\n",
      "delighted : [1, '-0.152409595318']\n",
      "god dammit : [1, '-0.152409595318']\n",
      "heartbreaker: kyle lowry : [1, '-0.152409595318']\n",
      "2/18 bilden : [1, '-0.152409595318']\n",
      "vegas : [1, '-0.152409595318']\n",
      "investigate : [1, '-0.152409595318']\n",
      "tough : [1, '-0.152409595318']\n",
      "goodbye : [1, '-0.152409595318']\n",
      "reporting : [1, '-0.152409595318']\n",
      "see champion : [1, '-0.152409595318']\n",
      "congratualations : [1, '-0.152409595318']\n",
      "says : [1, '-0.152409595318']\n",
      "top 10 : [1, '-0.152409595318']\n",
      "white house press briefing : [1, '-0.152409595318']\n",
      "potus : [1, '-0.152409595318']\n",
      "awesome : [1, '-0.152409595318']\n",
      "best picture actually : [1, '-0.152409595318']\n",
      "best original screenplay : [1, '-0.152409595318']\n",
      "pg : [1, '-0.152409595318']\n",
      "benghazi..$7 : [1, '-0.152409595318']\n",
      "omg...at : [1, '-0.152409595318']\n",
      "probably : [1, '-0.152409595318']\n",
      "poc : [1, '-0.152409595318']\n",
      "sally : [1, '-0.152409595318']\n",
      "rolex milgaus : [1, '-0.152409595318']\n",
      "march and april : [1, '-0.152409595318']\n",
      "front : [1, '-0.152409595318']\n",
      "blame : [1, '-0.152409595318']\n",
      "kate beckinsale at the : [1, '-0.152409595318']\n",
      "mellissa : [1, '-0.152409595318']\n",
      "no.78 : [1, '-0.152409595318']\n",
      "vanity fair party : [1, '-0.152409595318']\n",
      "due : [1, '-0.152409595318']\n",
      "cia director pompeo : [1, '-0.152409595318']\n",
      "dawsonville chase elliott : [1, '-0.152409595318']\n",
      "man kyle lowry : [1, '-0.152409595318']\n",
      "west wing : [1, '-0.152409595318']\n",
      "confide : [1, '-0.152409595318']\n",
      "twitter explodes : [1, '-0.152409595318']\n",
      "texas april 9th : [1, '-0.152409595318']\n",
      "wendy : [1, '-0.152409595318']\n",
      "sean spicer \"ivanka : [1, '-0.152409595318']\n",
      "thrilling : [1, '-0.152409595318']\n",
      "harry : [1, '-0.152409595318']\n",
      "lying : [1, '-0.152409595318']\n",
      "inspection : [1, '-0.152409595318']\n",
      "sarah paulson : [1, '-0.152409595318']\n",
      "dollars : [1, '-0.152409595318']\n",
      "revealed: sean spicer : [1, '-0.152409595318']\n",
      "massive : [1, '-0.152409595318']\n",
      "fraud : [1, '-0.152409595318']\n",
      "feb. 26, 2001 : [1, '-0.152409595318']\n",
      "demand : [1, '-0.152409595318']\n",
      "bill owens : [1, '-0.152409595318']\n",
      "april ryan : [1, '-0.152409595318']\n",
      "era : [1, '-0.152409595318']\n",
      "bodies....in : [1, '-0.152409595318']\n",
      "wp and cnn : [1, '-0.152409595318']\n",
      "investigation : [1, '-0.152409595318']\n",
      "sphincter : [1, '-0.152409595318']\n",
      "raptors at knicks : [1, '-0.152409595318']\n",
      "nears : [1, '-0.152409595318']\n",
      "love : [1, '-0.152409595318']\n",
      "toronto raptors : [1, '-0.152409595318']\n",
      "put on fox : [1, '-0.152409595318']\n",
      "mma : [1, '-0.152409595318']\n",
      "michael jordan : [1, '-0.152409595318']\n",
      "g'nite : [1, '-0.152409595318']\n",
      "mike flynn : [1, '-0.152409595318']\n",
      "p9 : [1, '-0.152409595318']\n",
      "gotta : [1, '-0.152409595318']\n",
      "michael keaton : [1, '-0.152409595318']\n",
      "almost : [1, '-0.152409595318']\n",
      "putting : [1, '-0.152409595318']\n",
      "gave terrorists : [1, '-0.152409595318']\n",
      "expect : [1, '-0.152409595318']\n",
      "venn : [1, '-0.152409595318']\n",
      "trump tuesday : [1, '-0.152409595318']\n",
      "calvin klein : [1, '-0.152409595318']\n",
      "new york : [1, '-0.152409595318']\n",
      "trump russia : [1, '-0.152409595318']\n",
      "celtics : [1, '-0.152409595318']\n",
      "monster energy : [1, '-0.152409595318']\n",
      "16th in the nba : [1, '-0.152409595318']\n",
      "all-star : [1, '-0.152409595318']\n",
      "unbelievable : [1, '-0.152409595318']\n",
      "fun : [1, '-0.152409595318']\n",
      "game-changer : [1, '-0.152409595318']\n",
      "king of gondor : [1, '-0.152409595318']\n",
      "marvel \"red carpet pose : [1, '-0.152409595318']\n",
      "take : [1, '-0.152409595318']\n",
      "kate hudson : [1, '-0.152409595318']\n",
      "the france : [1, '-0.152409595318']\n",
      "nasa : [1, '-0.152409595318']\n",
      "sean spicer on president trump : [1, '-0.152409595318']\n",
      "asg : [1, '-0.152409595318']\n",
      "especially : [1, '-0.152409595318']\n",
      "ruth negga : [1, '-0.152409595318']\n",
      "denzel : [1, '-0.152409595318']\n",
      "matt damon : [1, '-0.152409595318']\n",
      "madonna : [1, '-0.152409595318']\n",
      "enthusiasm : [1, '-0.152409595318']\n",
      "the dreamiest : [1, '-0.152409595318']\n",
      "worldwide : [1, '-0.152409595318']\n",
      "danica patrick : [1, '-0.152409595318']\n",
      "great american race : [1, '-0.152409595318']\n",
      "recap : [1, '-0.152409595318']\n",
      "hollywood : [1, '-0.152409595318']\n",
      "white helmets : [1, '-0.152409595318']\n",
      "kimmel : [1, '-0.152409595318']\n",
      "tonyoldman41: dreams : [1, '-0.152409595318']\n",
      "gene huber : [1, '-0.152409595318']\n",
      "managed : [1, '-0.152409595318']\n",
      "key : [1, '-0.152409595318']\n",
      "fair : [1, '-0.152409595318']\n",
      "sean spicer: the president : [1, '-0.152409595318']\n",
      "2016: spotlight : [1, '-0.152409595318']\n",
      "shout : [1, '-0.152409595318']\n",
      "chance : [1, '-0.152409595318']\n",
      "barry jenkins : [1, '-0.152409595318']\n",
      "raise : [1, '-0.152409595318']\n",
      "latest : [1, '-0.152409595318']\n",
      "raps : [1, '-0.152409595318']\n",
      "return : [1, '-0.152409595318']\n",
      "2018: tubelight : [1, '-0.152409595318']\n",
      "cory jo : [1, '-0.152409595318']\n",
      "family : [1, '-0.152409595318']\n",
      "collects white house staffers' phones in effort : [1, '-0.152409595318']\n",
      "signal and confide : [1, '-0.152409595318']\n",
      "all-star g kyle lowry : [1, '-0.152409595318']\n",
      "terrorists : [1, '-0.152409595318']\n",
      "dale jr : [1, '-0.152409595318']\n",
      "kellyanne : [1, '-0.152409595318']\n",
      "busch 15th : [1, '-0.152409595318']\n",
      "reports: kyle lowry : [1, '-0.152409595318']\n",
      "hillary : [1, '-0.152409595318']\n",
      "delayed streisand effect : [1, '-0.152409595318']\n",
      "thought : [1, '-0.152409595318']\n",
      "almost 38 : [1, '-0.152409595318']\n",
      "mcmurray : [1, '-0.152409595318']\n",
      "reported attempt : [1, '-0.152409595318']\n",
      "undergo wrist surgery : [1, '-0.152409595318']\n",
      "breaking : [1, '-0.152409595318']\n",
      "awkward : [1, '-0.152409595318']\n",
      "golden boot award : [1, '-0.152409595318']\n",
      "update: crash : [1, '-0.152409595318']\n",
      "frantically googles : [1, '-0.152409595318']\n",
      "uk : [1, '-0.152409595318']\n",
      "faye : [1, '-0.152409595318']\n",
      "all-star game : [1, '-0.152409595318']\n",
      "20:30 and 21:30 : [1, '-0.152409595318']\n",
      "9 daytona 500 : [1, '-0.152409595318']\n",
      "thankful : [1, '-0.152409595318']\n",
      "u : [1, '-0.152409595318']\n",
      "lucy : [1, '-0.152409595318']\n",
      "sources: lowry : [1, '-0.152409595318']\n",
      "hailee steinfeld : [1, '-0.152409595318']\n",
      "kate hudson at the : [1, '-0.152409595318']\n",
      "chris : [1, '-0.152409595318']\n",
      "trumped : [1, '-0.152409595318']\n",
      "spicer collects white house staffers' phones in effort : [1, '-0.152409595318']\n",
      "leakers : [1, '-0.152409595318']\n",
      "mexico : [1, '-0.152409595318']\n",
      "raptors' kyle lowry : [1, '-0.152409595318']\n",
      "leaked : [1, '-0.152409595318']\n",
      "manchester by the sea : [1, '-0.152409595318']\n",
      "nd : [1, '-0.152409595318']\n",
      "37.3 pts : [1, '-0.152409595318']\n",
      "sean spicer hunt : [1, '-0.152409595318']\n",
      "dear : [1, '-0.152409595318']\n",
      "canada : [1, '-0.152409595318']\n",
      "best visual effects : [1, '-0.152409595318']\n",
      "missed : [1, '-0.152409595318']\n",
      "got : [1, '-0.152409595318']\n",
      "congress : [1, '-0.152409595318']\n",
      "tl : [1, '-0.152409595318']\n",
      "khaled khatib : [1, '-0.152409595318']\n",
      "ford fusion : [1, '-0.152409595318']\n",
      "2017: moonlight : [1, '-0.152409595318']\n",
      "representation : [1, '-0.152409595318']\n",
      "breaking: raptors' kyle lowry : [1, '-0.152409595318']\n",
      "canadian : [1, '-0.152409595318']\n",
      "give : [1, '-0.152409595318']\n",
      "jackie chan : [1, '-0.152409595318']\n",
      "week 1 : [1, '-0.152409595318']\n",
      "curb : [1, '-0.152409595318']\n",
      "miller : [1, '-0.152409595318']\n",
      "get : [1, '-0.152409595318']\n",
      "russia/trump : [1, '-0.152409595318']\n",
      "4.3 apg : [1, '-0.152409595318']\n",
      "post : [1, '-0.152409595318']\n",
      "mickey mouse club : [1, '-0.152409595318']\n",
      "did : [1, '-0.152409595318']\n",
      "stop : [1, '-0.152409595318']\n",
      "37.3 ppg : [1, '-0.152409595318']\n",
      "lebanon : [1, '-0.152409595318']\n",
      "hbcus : [1, '-0.152409595318']\n",
      "follow : [1, '-0.152409595318']\n",
      "happening : [1, '-0.152409595318']\n",
      "today : [1, '-0.152409595318']\n",
      "ready : [1, '-0.152409595318']\n",
      "took : [1, '-0.152409595318']\n",
      "clear : [1, '-0.152409595318']\n",
      "sorry : [1, '-0.152409595318']\n",
      "4.3 ast : [1, '-0.152409595318']\n",
      "wrist surgery : [1, '-0.152409595318']\n",
      "sean spicer in december : [1, '-0.152409595318']\n",
      "russkis : [1, '-0.152409595318']\n",
      "muslim oscar : [1, '-0.152409595318']\n",
      "wrist : [1, '-0.152409595318']\n",
      "hands : [1, '-0.152409595318']\n",
      "e-mails of hrc : [1, '-0.152409595318']\n",
      "best director : [1, '-0.152409595318']\n",
      "award : [1, '-0.152409595318']\n",
      "metta world peace : [1, '-0.152409595318']\n",
      "get money : [1, '-0.152409595318']\n",
      "sad \"ralph : [1, '-0.152409595318']\n",
      "epic : [1, '-0.152409595318']\n",
      "paging brandon jennings : [1, '-0.152409595318']\n",
      "following moonlight : [1, '-0.152409595318']\n",
      "first amendment : [1, '-0.152409595318']\n",
      "american : [1, '-0.152409595318']\n",
      "royal rumble : [1, '-0.152409595318']\n",
      "7.3 reb : [1, '-0.152409595318']\n",
      "familiar : [1, '-0.152409595318']\n",
      "ryan gosling : [1, '-0.152409595318']\n",
      "dolan : [1, '-0.152409595318']\n",
      "mr spicer : [1, '-0.152409595318']\n",
      "taraji : [1, '-0.152409595318']\n",
      "over/under : [1, '-0.152409595318']\n",
      "need one yesterday : [1, '-0.152409595318']\n",
      "–sean spicer : [1, '-0.152409595318']\n",
      "lap 152 : [1, '-0.152409595318']\n",
      "want : [1, '-0.152409595318']\n",
      "anne frank center : [1, '-0.152409595318']\n",
      "raceday : [1, '-0.152409595318']\n",
      "wh : [1, '-0.152409595318']\n",
      "breaking update: following : [1, '-0.152409595318']\n",
      "ha : [1, '-0.152409595318']\n",
      "eddie redmayne : [1, '-0.152409595318']\n",
      "nba news : [1, '-0.152409595318']\n",
      "h/t : [1, '-0.152409595318']\n",
      "goid : [1, '-0.152409595318']\n",
      "races : [1, '-0.152409595318']\n",
      "context: 83 : [1, '-0.152409595318']\n",
      "sean spicer shreds : [1, '-0.152409595318']\n",
      "aiming : [1, '-0.152409595318']\n",
      "nominee : [1, '-0.152409595318']\n",
      "move : [1, '-0.152409595318']\n",
      "chrissy teigen : [1, '-0.152409595318']\n",
      "3-pt fg : [1, '-0.152409595318']\n",
      "shumpert : [1, '-0.152409595318']\n",
      "academy award : [1, '-0.152409595318']\n",
      "stop leaks : [1, '-0.152409595318']\n",
      "welcome : [1, '-0.152409595318']\n",
      "see : [1, '-0.152409595318']\n",
      "public : [1, '-0.152409595318']\n",
      "loved : [1, '-0.152409595318']\n",
      "janelle : [1, '-0.152409595318']\n",
      "credit : [1, '-0.152409595318']\n",
      "22.8 ppg : [1, '-0.152409595318']\n",
      "sports alert: the toronto raptors : [1, '-0.152409595318']\n",
      "mar-a-lago : [1, '-0.152409595318']\n",
      "sean spicer\" good : [1, '-0.152409595318']\n",
      "lgbt : [1, '-0.152409595318']\n",
      "happened : [1, '-0.152409595318']\n",
      "hopes : [1, '-0.152409595318']\n",
      "easter bunny at the white house : [1, '-0.152409595318']\n",
      "aims : [1, '-0.152409595318']\n",
      "2017 champion : [1, '-0.152409595318']\n",
      "**********************************************************\n",
      "Total number of tokens processed: 7141\n",
      "Total number of NEs extracted: 769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''This is the main module. I am not explicitly writing it as a function as I am not sure what argument you are \n",
    "passing.However you can call this whole cell as a function and it will call the rest of the functions in my module\n",
    "to extract candidates and features\n",
    "'''\n",
    "\n",
    "'''#reads input from the database file and converts to a dataframe. You can change this part accordingly and\n",
    "#directly convert argument tuple to the dataframe'''\n",
    "\n",
    "#Collection.csv\n",
    "df = read_csv('/home/satadisha/Desktop/GitProjects/ELTweetTracker/500Sample.csv', index_col='ID', header=0, encoding='utf-8')\n",
    "\n",
    "#output.csv\n",
    "df_out= DataFrame(columns=('tweetID', 'sentID', 'hashtags', 'user', 'usertype', 'TweetSentence', 'phase1Candidates'))\n",
    "\n",
    "#%%timeit -o\n",
    "#module_capital_punct.main:\n",
    "'''I am running this for 100 iterations for testing purposes. Of course you no longer need this for loop as you are\n",
    "#running one tuple at a time'''\n",
    "\n",
    "count=0\n",
    "ne_count=0\n",
    "userMention_count=0\n",
    "token_count=0\n",
    "\n",
    "NE_list_phase1=[]\n",
    "UserMention_list=[]\n",
    "ME_EXTR=Mention.Mention_Extraction()\n",
    "\n",
    "#--------------------------------------PHASE I---------------------------------------------------\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    if count<500:\n",
    "        #tweetText=unicode(row['Tweets']).encode('utf-8')\n",
    "        #index\n",
    "        hashtags=str(row['Discussion'])\n",
    "        user=str(row['User'])\n",
    "        userType=str(row['User Type'])\n",
    "        tweetText=str(row['TweetText'])\n",
    "        \n",
    "        #print(str(index)+\". \"+userType+\":=>\\n\"+tweetText)\n",
    "        \n",
    "        #capitalization module\n",
    "        #if all words are capitalized:\n",
    "        if tweetText.isupper():\n",
    "            print(\"\",end=\"\")\n",
    "            #print (\"All caps module\\n\")\n",
    "        elif tweetText.islower():\n",
    "            print(\"\",end=\"\")\n",
    "            #print (\"All lower module\\n\")\n",
    "        else:\n",
    "            ne_List_final=[]\n",
    "            userMention_List_final=[]\n",
    "            #pre-modification: returns word list split at whitespaces; retains punctuation\n",
    "            tweetSentences=list(filter (lambda sentence: len(sentence)>1, tweetText.split('\\n')))\n",
    "            tweetSentenceList_inter=flatten(list(map(lambda sentText: sent_tokenize(sentText.lstrip().rstrip()),tweetSentences)),[])\n",
    "            tweetSentenceList=list(filter (lambda sentence: len(sentence)>1, tweetSentenceList_inter))\n",
    "            \n",
    "            for sen_index in range(len(tweetSentenceList)):\n",
    "                sentence=tweetSentenceList[sen_index]\n",
    "                #print(sentence)\n",
    "                tweetWordList= sentence.split()\n",
    "                \n",
    "                token_count+=len(tweetWordList)\n",
    "                #print (tweetWordList)\n",
    "                #returns position of words that are capitalized\n",
    "                tweetWordList_cappos = list(map(lambda element : element[0], filter(lambda element : capCheck(element[1]), enumerate(tweetWordList))))\n",
    "                \n",
    "                #returns list of @userMentions\n",
    "                userMentionswPunct=list(filter(lambda phrase: phrase.startswith('@'), tweetWordList))\n",
    "                userMentions=list(map(lambda mention: mention.rstrip(string.punctuation), userMentionswPunct))\n",
    "                \n",
    "                #non @usermentions are processed in this function to find non @, non hashtag Entities---- thread 1\n",
    "                q = queue.Queue()\n",
    "                threading.Thread(target=trueEntity_process, args=(tweetWordList_cappos,tweetWordList,q)).start()\n",
    "                #ne_List_allCheck= trueEntity_process(tweetWordList_cappos,tweetWordList)\n",
    "\n",
    "                userMention_count+=len(userMentions)\n",
    "                userMention_List_final+=userMentions                \n",
    "                #function to process and store @ user mentions---- thread 2\n",
    "                threading.Thread(target=ME_EXTR.ComputeAll, args=(userMention_List_final,)).start()\n",
    "                \n",
    "                ne_List_allCheck= q.get()\n",
    "                ne_count+=len(ne_List_allCheck)\n",
    "                ne_List_final+=ne_List_allCheck\n",
    "                \n",
    "                #write row to output dataframe\n",
    "                phase1Out=\"\"\n",
    "                for candidate in ne_List_allCheck:\n",
    "                    phase1Out+=candidate.phraseText.strip()+\"|| \" \n",
    "                outrow=[str(index), str(sen_index), hashtags, user, userType, sentence, phase1Out]\n",
    "                df_out.loc[len(df_out)]=outrow\n",
    "\n",
    "            for candidate in ne_List_final:\n",
    "                insert_dict (candidate)\n",
    "            '''printList(ne_List_final)\n",
    "            if(userMention_List_final):\n",
    "                print(userMention_List_final)'''\n",
    "            \n",
    "            NE_list_phase1+=ne_List_final\n",
    "            UserMention_list+=userMention_List_final\n",
    "            #print (\"\\n\")\n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "sorted_NE_container =OrderedDict(sorted(NE_container.items(), key=lambda t: t[1],reverse=True))\n",
    "frequency_array = np.array(list(sorted_NE_container.values()))\n",
    "zscore_array=stats.zscore(frequency_array)\n",
    "\n",
    "index=0\n",
    "#for key, val in sorted_NE_container:\n",
    "for key in sorted_NE_container.keys():\n",
    "    val=[sorted_NE_container[key], str(zscore_array[index])]\n",
    "    index+=1\n",
    "    sorted_NE_container[key]=val\n",
    "    print (key+\" : \"+str(sorted_NE_container[key]))\n",
    "\n",
    "#ME_EXTR.PrintDictionary()\n",
    "print(\"**********************************************************\")\n",
    "\n",
    "print(\"Total number of tokens processed: \"+str(token_count))\n",
    "print (\"Total number of NEs extracted: \"+str(ne_count))\n",
    "\n",
    "df_out.to_csv('output.csv')\n",
    "#--------------------------------------PHASE I---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_NE_container))\n",
    "#word=\"hahaha\"\n",
    "text=\"POS LIAR\"\n",
    "print(text.isupper())\n",
    "phrase=(text.lstrip(string.punctuation)).rstrip(string.punctuation).strip()\n",
    "#p1= re.compile(r'[A-Z]*\\s*[A-Z]{2,}[^A-Za-z]*\\s*[A-Za-z]+')\n",
    "p1= re.compile(r'[A-Z]*\\s*[A-Z]{4,}[^A-Za-z]*\\s*[A-Za-z]+')\n",
    "match_lst = p1.findall(phrase)\n",
    "if match_lst:\n",
    "    if not phrase.isupper():\n",
    "        print (\"GOTIT: \"+phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
